{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Написать свой код к разделам 1 - 5 согласно заданиям для всех фрагментов, помеченных как: <ВАШ КОД:>"
      ],
      "metadata": {
        "id": "aWTJO2sXO8Hs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Поиск по дереву Монте-Карло (MCTS) — это эвристический алгоритм поиска,\n",
        "который показывает отличные результаты в таких сложных областях, как го и\n",
        "шахматы. Алгоритм строит дерево поиска, итеративно обходит его и оценивает его\n",
        "узлы с помощью моделирования методом Монте-Карло.\n"
      ],
      "metadata": {
        "id": "kMf2fWa8ZpwU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 Предварительные действия"
      ],
      "metadata": {
        "id": "zD8qV4ZchaD0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_2ATKnPoJiix"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# Этот код создает виртуальный дисплей для рисования игровых изображений\n",
        "# Это не будет иметь никакого эффекта, если на вашей машине есть монитор\n",
        "import os\n",
        "\n",
        "# Устанавливаем DISPLAY на значение ':1' (виртуальный дисплей)\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        " os.environ['DISPLAY'] = ':1'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сначала нужно создать оболочку для сред Gym, позволяющую сохранять и загружать игровые состояния для облегчения возврата."
      ],
      "metadata": {
        "id": "aexuj7aAi9Eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gym\n",
        "from gym.core import Wrapper\n",
        "from pickle import dumps, loads\n",
        "from collections import namedtuple"
      ],
      "metadata": {
        "id": "bk7ttHae-rro"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Контейнер для хранения результатов выполнения действия\n",
        "ActionResult = namedtuple(\n",
        "    \"action_result\", (\"snapshot\", \"observation\", \"reward\", \"is_done\", \"info\"))\n",
        "\n",
        "class WithSnapshots(Wrapper):\n",
        "    \"\"\"\n",
        "    Создает оболочку, поддерживающую сохранение и загрузку состояний среды\n",
        "    Это нужно для алгоритмов планирования, таких как MCTS\n",
        "\n",
        "    Можно использовать self.render(), это создаст окно, которое нельзя замариновать\n",
        "    Таким образом, нужно будет вызвать self.close(), прежде чем травление снова заработает\n",
        "    \"\"\"\n",
        "    # Метод для сохранения текущего состояния среды (env) в виде снимка перед выполнением действия\n",
        "    def get_snapshot(self, render=False):\n",
        "        \"\"\"\n",
        "        Загружает сохраненный снимок в текущую среду\n",
        "        :returns: состояние среды, которое можно загрузить с помощью load_snapshot\n",
        "        Снимки гарантируют одинаковое поведение env при каждой загрузке\n",
        "        Предупреждение! Снимки могут быть произвольными вещами (строки, целые числа, json, кортежи)\n",
        "\n",
        "        \"\"\"\n",
        "        if render:\n",
        "            self.render()  # Закрываем всплывающие окна, если есть\n",
        "            self.close()\n",
        "\n",
        "        if hasattr(self.unwrapped, 'viewer') and self.unwrapped.viewer is not None:\n",
        "          # Закрываем viewer, чтобы избежать проблем с сохранением\n",
        "            self.unwrapped.viewer.close()\n",
        "            self.unwrapped.viewer = None\n",
        "        # Создаем снимок состояния без графического компонента\n",
        "        state = self.env.unwrapped.state  # или другие компоненты состояния, которые вы хотите сохранить\n",
        "        # Сохраняем состояние среды с помощью pickle\n",
        "        return dumps(state)\n",
        "\n",
        "    # Метод для восстановления состояния среды из сохраненного ранее снимка (в предыдущее состояние)\n",
        "    def load_snapshot(self, snapshot, render=False):\n",
        "        \"\"\"\n",
        "        Загружает сохраненный снимок в текущую среду\n",
        "        Не следует менять снапшот на месте\n",
        "        \"\"\"\n",
        "        # Проверяем, что запись не активна, чтобы избежать ошибок\n",
        "        assert not hasattr(self, \"_monitor\") or hasattr(\n",
        "            self.env, \"_monitor\"), \"не могу вернуться во время записи\"\n",
        "        if render:\n",
        "            self.render()  # Закрываем всплывающие окна, так как мы не можем загрузиться в них\n",
        "            self.close()\n",
        "        # Загружаем состояние среды из снапшота\n",
        "        self.env.unwrapped.state = loads(snapshot)\n",
        "\n",
        "    # Метод загружает сохраненное состояние среды, выполняет указанные действия, сохранняет новое состояние среды и возвращает результат и нвоый снимок\n",
        "    def get_result(self, snapshot, action):\n",
        "        \"\"\"\n",
        "        Удобная функция, которая\n",
        "        - загружает снимок,\n",
        "        - совершает действие через self.step,\n",
        "        - и снова делает снимок :)\n",
        "        :returns: следующий снимок, next_observation, награда, is_done, информация\n",
        "        По сути, он возвращает следующий снимок и все, что вернул бы env.step\n",
        "        \"\"\"\n",
        "        # Загружаем состояние из переданного снапшота\n",
        "        self.load_snapshot(snapshot)\n",
        "\n",
        "        next_observation, reward, is_done, truncated, info = self.step(action)\n",
        "\n",
        "        # Делаем новый снимок текущего состояния среды\n",
        "        next_snapshot = self.get_snapshot()\n",
        "\n",
        "        # Возвращаем результат действия и новый снимок\n",
        "        return ActionResult(\n",
        "            next_snapshot,    # Снимок нового состояния\n",
        "            next_observation, # Новое наблюдение после действия\n",
        "            reward,           # Награда\n",
        "            is_done,          # Завершение эпизода\n",
        "            info              # Информация\n",
        "        )"
      ],
      "metadata": {
        "id": "G0Etq_qOi8I5"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Пробы со снимками"
      ],
      "metadata": {
        "id": "KtSlJN16x2NR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сначала сбрасываем окружение и сохраняем его, далее случайным образом играем какие-то действия и восстанавливаем наше\n",
        "окружение из снимка. Оно должно быть таким же, как наше предыдущее начальное\n",
        "состояние"
      ],
      "metadata": {
        "id": "3jIGdKQUyVCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание окружения\n",
        "env = WithSnapshots(gym.make(\"CartPole-v1\", render_mode=\"rgb_array\"))\n",
        "# Сбрасываем среду, чтобы начать новый эпизод\n",
        "env.reset()\n",
        "# Получаем количество доступных действий в среде\n",
        "n_actions = env.action_space.n"
      ],
      "metadata": {
        "id": "UwV6gdiN2xoS"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"initial_state:\")\n",
        "# Получаем начальное изображение среды\n",
        "initial_state = env.render()\n",
        "\n",
        "# Отображаем изображение\n",
        "plt.imshow(initial_state)\n",
        "plt.axis('off')  # Выключить оси\n",
        "plt.show()\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "lPeZTXAL21kZ",
        "outputId": "04c00d8f-b263-482c-dc09-c21018af05c7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial_state:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание первого снимка\n",
        "snap0 = env.get_snapshot()"
      ],
      "metadata": {
        "id": "4JQ5lQc86waJ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проигрывание без снимков (быстрее - случайный)\n",
        "while True:\n",
        "    # Выполняем случайное действие и проверяем, завершен ли эпизод\n",
        "    is_done = env.step(env.action_space.sample())[2]\n",
        "    if is_done:\n",
        "        print(\"Whoops! We died!\")\n",
        "        break\n",
        "print(\"final state:\")\n",
        "plt.imshow(env.render())\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "-bdqpOMd_oh_",
        "outputId": "4512fee9-e7dc-4717-afe7-499ea84ad359"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whoops! We died!\n",
            "final state:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Перезагрузка первичного состояния\n",
        "env.load_snapshot(snap0)\n",
        "print(\"\\n\\nAfter loading snapshot\")\n",
        "plt.imshow(env.render())\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "meKZjlwE_0qi",
        "outputId": "079255c9-5ec4-430b-b727-8fc90fd736e2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "After loading snapshot\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Получить результат выполнения случайного действия из состояния snap0(snapshot, observation, reward, is_done, info)\n",
        "res = env.get_result(snap0, env.action_space.sample())\n",
        "\n",
        "# Извлекаем данные из результата (новый снимок, наблюдение, награда)\n",
        "snap1, observation, reward = res[:3]\n",
        "\n",
        "# Второй шаг с новым состоянием (snap1)\n",
        "res2 = env.get_result(snap1, env.action_space.sample())\n"
      ],
      "metadata": {
        "id": "14QcQur6yW5V"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3  MCTS: поиск по дереву Монте-Карло\n"
      ],
      "metadata": {
        "id": "-ecabdH41_kY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы начнем с реализации класса Node — простого класса, который действует как узел MCTS и поддерживает некоторые шаги алгоритма MCTS"
      ],
      "metadata": {
        "id": "aG_8ocQ12CAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверим, что объект env экземпляр класса WithSnapshots\n",
        "assert isinstance(env, WithSnapshots)"
      ],
      "metadata": {
        "id": "P26M52ZN2E5l"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    \"\"\"Узел дерева для MCTS\n",
        "    Каждый узел соответствует результату выполнения определенного действия (self.action)\n",
        "    в определенном состоянии (самородитель) и, по сути, является одной рукой в многоруком\n",
        "    бандите, который мы моделируем в этом состоянии.\"\"\"\n",
        "\n",
        "    # Метаданные:\n",
        "    parent = None  # Родительский узел\n",
        "    qvalue_sum = 0.  # Сумма Q-значений из всех визитов (numerator) (сумма наград)\n",
        "    times_visited = 0  # Счетчик визитов (denominator) (чтобы учитывать количество попыток)\n",
        "\n",
        "    def __init__(self, parent, action):\n",
        "        \"\"\"\n",
        "        Создает пустой узел без дочерних элементов\n",
        "        Делает это, совершая действие и записывая результат\n",
        "        :param parent: родительский узел\n",
        "        :param action: действие для фиксации с родительского узла\n",
        "        \"\"\"\n",
        "        self.parent = parent\n",
        "        self.action = action\n",
        "        self.children = set()  # Набор дочерних узлов\n",
        "\n",
        "        # Получение результатов действий и их сохранение\n",
        "        res = env.get_result(parent.snapshot, action)\n",
        "        # Состояние, наблюдения, награда, завершенность эпизода\n",
        "        self.snapshot, self.observation, self.immediate_reward, self.is_done, _ = res\n",
        "\n",
        "    # Метод для опредления является ли узел листом (без дочерних листов)\n",
        "    # Для определения достиг ли алгоритм конечного состояния в дереве (если нет детей, то конечная точка)\n",
        "    def is_leaf(self):\n",
        "        return len(self.children) == 0\n",
        "\n",
        "    # Метод для определения является ли текущий узел корнем дерева (начальное состояние, с котрого начинается процесс поиска)\n",
        "    def is_root(self):\n",
        "        return self.parent is None\n",
        "\n",
        "    # Метод для оценки Q-значения узла\n",
        "    # Представляет собой среднюю награду, полученную от всех посещений этого узла\n",
        "    # Если узел был посещен хотя бы один раз, то метод возвращает среднее значение\n",
        "    # Если узел не был посещен, то метод возвращает 0\n",
        "    def get_qvalue_estimate(self):\n",
        "        return self.qvalue_sum / self.times_visited if self.times_visited != 0 else 0\n",
        "\n",
        "    # Метод для вычисления оценки ucb1\n",
        "    # Оценка UCB1 используется для балансировки между эксплуатацией (выбором действий с лучшими результатами)\n",
        "    # и исследованием (выбором действий с наименьшим числом посещений для сбора доп информации)\n",
        "    def ucb_score(self, scale=10, max_value=1e100):\n",
        "        \"\"\"\n",
        "        Вычисляет верхнюю границу ucb1, используя текущее значение и количество посещений для узла и его родителя\n",
        "\n",
        "        :param scale: Умножает на это верхнюю границу. Из неравенства Хёффдинга предполагается, что диапазон вознаграждения равен [0, шкала]\n",
        "        :param max_value: значение, которое возвращается для узлов, которые еще не были посещены\n",
        "        \"\"\"\n",
        "        # Если узел не был посещен, возвращаем максимально возможную оценку\n",
        "        if self.times_visited == 0:\n",
        "            return max_value\n",
        "\n",
        "        # Вычисляем аддитивный компонент ucb-1, который регулирует степень неопределенности\n",
        "        # Эта часть поощряет исследование узлов, которые были посещены меньше, так как они могут быть недооценены\n",
        "        U = np.sqrt(np.log(self.parent.times_visited) / self.times_visited)\n",
        "        # Возвращаем итоговую оценку UCB, которая состоит из среднего Q-значения и компонента неопределенности\n",
        "        return self.get_qvalue_estimate() + scale * U\n",
        "\n",
        "    # Метод для выбора узла с наивысшей оценкой для дальнейшего расширения\n",
        "    def select_best_leaf(self):\n",
        "        \"\"\"\n",
        "        Выбирает лист с наивысшим приоритетом для расширения\n",
        "        Делает это, рекурсивно выбирая узлы с лучшим результатом UCB-1, пока не достигнет листа\n",
        "        \"\"\"\n",
        "        if self.is_leaf():\n",
        "            return self\n",
        "        children = self.children # Если не лист, то выбираем дочерние узлы\n",
        "\n",
        "        # Ищем дочерний узел с наивысшей оценкой UCB\n",
        "        best_child = max(self.children, key=lambda child: child.ucb_score())\n",
        "        # Возвращает оценку для каждого дочернего узла, основываясь на его количестве посещений и текущем значении\n",
        "        return best_child.select_best_leaf()\n",
        "\n",
        "    # Метод расширяет дерево, добавляя новые возможности для дальнейших шагов\n",
        "    def expand(self):\n",
        "        \"\"\"\n",
        "        Расширяет текущий узел, создавая все возможные дочерние узлы\n",
        "        Затем возвращается один из этих детей\n",
        "        \"\"\"\n",
        "        assert not self.is_done, \"не может расширяться из терминального состояния\"\n",
        "\n",
        "        # Для каждого возможного действия генерируем новый дочерний узел\n",
        "        # n_actions — общее количество возможных действий\n",
        "        for action in range(n_actions):\n",
        "            self.children.add(Node(self, action))  # Для каждого действия создаем новый дочерний узел\n",
        "\n",
        "        # Возвращаем лучший дочерний узел\n",
        "        return self.select_best_leaf()\n",
        "\n",
        "    # Метод отвечает за симуляцию игры от текущего состояния узла до терминального состояния\n",
        "    def rollout(self, t_max=10 ** 4):\n",
        "        \"\"\"\n",
        "        Играйте в игру от этого состояния до конца (готово) или за t_max шагов\n",
        "        На каждом этапе выбирайте действие случайным образом\n",
        "        Вычислите сумму наград от текущего состояния до конца эпизода\n",
        "\n",
        "        Примечание 1: используйте env.action_space.sample() для выбора случайного действия\n",
        "        Примечание 2: если узел является терминальным (self.is_done имеет значение True), просто верните self.immediate_reward\n",
        "        \"\"\"\n",
        "        # Устанавливаем среду в состояние, сохраненное в snapshot\n",
        "        env.load_snapshot(self.snapshot)\n",
        "        obs = self.observation # Состояние в текущий момент времени\n",
        "        is_done = self.is_done # Проверка, завершен ли эпизод\n",
        "        total_reward = 0  # Сумма вознаграждений\n",
        "\n",
        "        # Выполняем шаги до завершения эпизода или достижения максимального числа шагов\n",
        "        for _ in range(t_max):\n",
        "            if is_done:\n",
        "                break  # Если эпизод завершен, выходим из цикла\n",
        "\n",
        "            # Выбираем случайное действие\n",
        "            action = env.action_space.sample()\n",
        "            # Выполняем выбранное действие в среде и получаем новое состояние и награду\n",
        "            obs, reward, is_done, info, _ = env.step(action)\n",
        "\n",
        "            total_reward += reward\n",
        "\n",
        "        # Возвращаем сумму наград после выполнения всех шагов\n",
        "        return total_reward\n",
        "\n",
        "    # Метод для обновления статистики узла, а затем передает информацию к родительским узлам\n",
        "    def propagate(self, child_qvalue):\n",
        "        \"\"\"\n",
        "        Использует дочернее Q-значение (сумму вознаграждений) для рекурсивного обновления родителей\n",
        "        \"\"\"\n",
        "        # Текущее Q-значение — это награда на шаге + вознаграждение от дочернего узла\n",
        "        my_qvalue = self.immediate_reward + child_qvalue\n",
        "\n",
        "        # Обновляем сумму Q-значений и количество посещений\n",
        "        self.qvalue_sum += my_qvalue\n",
        "        self.times_visited += 1\n",
        "\n",
        "        # Рекурсивно обновляем родительский узел\n",
        "        if not self.is_root():\n",
        "            self.parent.propagate(my_qvalue)\n",
        "\n",
        "    # Метод выполняет рекурсивное удаление узла и всех его дочерних узлов\n",
        "    def safe_delete(self):\n",
        "        \"\"\"Безопасное удаление для предотвращения утечек памяти в некоторых версиях Python\"\"\"\n",
        "        del self.parent  # Удаляем ссылку на родительский узел\n",
        "        for child in self.children:\n",
        "            child.safe_delete()  # Рекурсивно удаляем все дочерние узлы\n",
        "        del self  # Удаляем текущий узел\n",
        "\n",
        "\n",
        "class Root(Node):\n",
        "    def __init__(self, snapshot, observation):\n",
        "        \"\"\"\n",
        "        Создает специальный узел, который действует как корень дерева.\n",
        "\n",
        "        :snapshot: Снимок (из env.get_snapshot), с которого можно начать планирование\n",
        "        :observation: Последнее наблюдение за окружающей средой\n",
        "        \"\"\"\n",
        "        self.parent = None  # Корневой узел не имеет родителя\n",
        "        self.children = set()  # Выбор дочернего узла\n",
        "        # root: загрузка снимка и наблюдение\n",
        "        self.snapshot = snapshot  # Снимок состояния среды\n",
        "        self.observation = observation  # Последнее наблюдение\n",
        "        self.immediate_reward = 0  # Награда на текущем шаге\n",
        "        self.is_done = False  # Эпизод еще не завершен\n",
        "\n",
        "    @staticmethod\n",
        "    def from_node(node):\n",
        "        \"\"\"Инициализирует узел как root\"\"\"\n",
        "        root = Root(node.snapshot, node.observation)\n",
        "        # Копируем данные из существующего узла\n",
        "        copied_fields = [\"qvalue_sum\", \"times_visited\", \"children\", \"is_done\"]\n",
        "        for field in copied_fields:\n",
        "            setattr(root, field, getattr(node, field))\n",
        "        return root\n"
      ],
      "metadata": {
        "id": "KmKi5t8y27yi"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 Основной цикл MCTS"
      ],
      "metadata": {
        "id": "a0mYajZ5Cu8_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Алгоритм:\n",
        "- выбираем лучший лист\n",
        "- если узел не терминальный, то создаем дочерние для всех действий и выбираем один для дальнейшего исследования\n",
        "- играем начиная с текущего состояния и до конца\n",
        "- после симуляции, обновляем родительские узлы с полученной наградой"
      ],
      "metadata": {
        "id": "ubBsRVpoC--0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plan_mcts(root, n_iters=10):\n",
        "    \"\"\"\n",
        "    Строит дерево с поиском по дереву Монте-Карло для n_iters итераций\n",
        "    :param root: узел дерева для планирования\n",
        "    :param n_iters: сколько циклов select-expand-simulate-propagate сделать\n",
        "    \"\"\"\n",
        "    for _ in range(n_iters):\n",
        "        # Выбор лучшего листа\n",
        "        # Используем метод select_best_leaf для выбора узла с наивысшей оценкой\n",
        "        node = root.select_best_leaf()\n",
        "\n",
        "        # Если узел терминальный (игра завершена), то все развертывания с этого узла имеют 0 награды\n",
        "        if node.is_done:\n",
        "            node.propagate(0)\n",
        "        else:\n",
        "            # Развертывание  лучшего листа и создание всевозможных дочерних узлов с наивысшей оценкой\n",
        "            child = node.expand()\n",
        "\n",
        "            # Выполняем случайное действие до завершения эпизода или достижения максимального числа шагов\n",
        "            reward = child.rollout()  # Получаем награду используется для обнуления узлов\n",
        "\n",
        "            # Распространение результатов вверх\n",
        "            child.propagate(reward)\n"
      ],
      "metadata": {
        "id": "XYIWO4xbCyhw"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5 Планирование и запуск"
      ],
      "metadata": {
        "id": "N3XHuTovxC6F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Используем реализацию MCTS, чтобы найти оптимальную политику"
      ],
      "metadata": {
        "id": "OkixQXQnxF5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация среды и корневого узла\n",
        "env = WithSnapshots(gym.make(\"CartPole-v1\"))  # Создаём среду с поддержкой снимков\n",
        "root_observation = env.reset()  # Сбрасываем среду и получаем начальное наблюдение\n",
        "root_snapshot = env.get_snapshot()  # Создаём снимок текущего состояния среды\n",
        "root = Root(root_snapshot, root_observation)  # Создаём корневой узел для дерева MCTS\n",
        "\n",
        "# Планируем дерево поиска MCTS\n",
        "plan_mcts(root, n_iters=1000)  # Выполняем планирование на 1000 итераций"
      ],
      "metadata": {
        "id": "L0oLi0ElxFid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcd88c5e-2073-4955-cb0f-fd0ea453cdad"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/envs/classic_control/cartpole.py:177: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned terminated = True. You should always call 'reset()' once you receive 'terminated = True' -- any further steps are undefined behavior.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from itertools import count\n",
        "\n",
        "# Инициализация тестовой среды\n",
        "total_reward = 0  # Общая сумма наград\n",
        "# Создаем новую среду для тестирования\n",
        "test_env = WithSnapshots(gym.make(\"CartPole-v1\", render_mode=\"rgb_array\"))\n",
        "\n",
        "# Сбрасываем тестовую среду\n",
        "test_env.reset()\n",
        "\n",
        "# Оборачиваем среду в RecordVideo\n",
        "test_env = RecordVideo(test_env, video_folder='videos', name_prefix='test_run')\n",
        "\n",
        "# Визуализация и взаимодействие с тестовой средой\n",
        "for i in count():\n",
        "    # Выбор лучшего дочернего узла на основе среднего значения наград\n",
        "    best_child = max(root.children, key=lambda child: child.get_qvalue_estimate())\n",
        "\n",
        "    # Выполнение действия, связанного с лучшим узлом\n",
        "    s, r, done, info, _ = test_env.step(best_child.action)\n",
        "    print(f\"Step {i}, State: {s}, Reward: {r}, Done: {done}\")\n",
        "\n",
        "    # Отображаем текущее состояние среды\n",
        "    clear_output(True)\n",
        "    plt.title(f\"Step {i}\")\n",
        "\n",
        "    # Используем render для отображения изображения\n",
        "    img = test_env.unwrapped.render()\n",
        "    if img is not None:\n",
        "        plt.imshow(img)  # Рендерим изображение среды\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"Error: render returned None\")\n",
        "\n",
        "    # Обновляем всю награду\n",
        "    total_reward += r\n",
        "\n",
        "    # Если эпизод завершён, выводим результат и завершаем цикл\n",
        "    if done:\n",
        "        print(\"Finished with reward = \", total_reward)\n",
        "        # Закрываем тестовую среду\n",
        "        test_env.close()\n",
        "        break\n",
        "\n",
        "    # Удаляем из дерева все дочерние узлы, кроме лучшего\n",
        "    for child in root.children:\n",
        "        if child != best_child:\n",
        "            child.safe_delete()\n",
        "\n",
        "    # Объявляем лучшего потомка новым корнем дерева\n",
        "    root = Root.from_node(best_child)\n",
        "\n",
        "    # Проверяем, не закончились ли листья дерева\n",
        "    assert not root.is_leaf(), \\\n",
        "        \"У нас закончилось дерево! Нужно больше планирования! Попробуйте вырастить дерево прямо внутри цикла.\"\n",
        "\n",
        "    # Дополнительное планирование для роста дерева\n",
        "    plan_mcts(root, n_iters=100)  # Выполняем дополнительные итерации планирования\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "AINXJMT5Hcl8",
        "outputId": "c06306d5-c045-4ebd-dfa6-5a25491ddece"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished with reward =  47.0\n"
          ]
        }
      ]
    }
  ]
}